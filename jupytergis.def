Bootstrap: docker
From: quay.io/galaxy/docker-jupyter-notebook:25.12.1

%environment
    export PATH="/opt/ollama/bin:${PATH}"

%post
    # Install python and jupyter packages
    conda install --yes \
        bioblend galaxy-ie-helpers \
        qgis && \
        conda clean --all -y && \
        fix-permissions /opt/conda

    pip install jupytergis==0.13.2 'jupyter-ai[all]'

    # Set permissions for Jupyter and Galaxy mount points
    chown -R $NB_USER:users /home/$NB_USER/ /import /export/ && \
        chmod -R 777 /home/$NB_USER/ /import /export/

    # Create a directory for Ollama
    mkdir -p /opt/ollama/bin /opt/ollama/models && \
        chown -R $NB_USER:users /opt/ollama

    # Download and extract Ollama binary (amd64 assumed)
    cd /opt/ollama && \
        curl -L https://ollama.com/download/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz && \
        tar -xzf ollama-linux-amd64.tgz && \
        rm ollama-linux-amd64.tgz

    # Pre-pull the llama3.2 model
    ollama serve & \
        until curl -s http://localhost:11434/api/tags > /dev/null; do sleep 1; done && \
        ollama pull llama3.2 && \
        pkill ollama

    # Make startup scripts executable
    chmod +x /usr/local/bin/start-ollama.sh

%files
    jupyter_notebook_config.py /home/${NB_USER}/.jupyter/jupyter_notebook_config.py
    jupyter_lab_config.py /home/${NB_USER}/.jupyter/jupyter_lab_config.py
    start-ollama.sh /usr/local/bin/start-ollama.sh

%runscript
    exec /startup.sh
